{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINM 36700 \n",
    "# HOMEWORK #5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Case\n",
    "1. The factors used by Fama & French includes (other than MKT):\n",
    "    - size factor (i.e. size of a firm or the market cap of a firm). They observed that, all else being equal, firms with smaller market caps have higher average returns over time relative to firms with larger market caps. Several pieces of papers have been pointed to various reasonings for this effect, but the clearest seems to be done by various papers by AQR, which posits that most of the effects are noise (i.e. volatility of junky small firms), and that by controlling for these factors, can we see a robust size premia exists only for quality firms. See Size Matters, If You Can Control Your Junk by AQR's team. This can be measured by grouping stocks into their percentiles by market cap.\n",
    "    - value factor (i.e. specifically book value to market cap). This effect is potentially due to either: a compensation for risk taken for a potentially less profitable and/or more distressed company, or investors mis-pricing assets due to a wrong read of information. The truth probably lies somewhere in the middle of this. There are multiple ways to measure the value approach (I would argue that the measure that provides the highest sustained premia comes from EV/EBIT), but the Fama-French approach was using B/M and separating these into quintles.\n",
    "    - profitability factor (i.e. ratio of firm's operating profit to book value). Fama and Frehcnh used these and sorted companies from high to low profitability, with the argument being that higher profitability yield higher quality companies yield higher returns. Interestingly, this effect might not be as robust as expected, as removing profitability might yield higher annual returns (see Deep Value by Tobias Carlisle). \n",
    "    - investment factor (i.e. percentage change in the value of the firm's assets over the year). The theory is that the firm's increased investment signals lack of future earnings. \n",
    "\n",
    "    The one factor not included by Fama and French but is significant is the momentum factor. The effects are highly debatable. Fama and French have tested and controlled for this factor, but similarly, others have shown outperformance using the momentum signal. In the case, it is measured by sorting stocks based on their appreciation in the previous year. \n",
    "\n",
    "2. The factor portfolio could be long only or can can be approached via a long-short manner (short lowest quintle long highest quintile). Traditionally, the companies are weighted by market cap. \n",
    "\n",
    "3. Not heavily discussed in case. \n",
    "\n",
    "4. No 1-6 in case. Figure 6 references momemtum quintiles\n",
    "\n",
    "5. Traditional factor ETFs have weights based on the market cap of the companies, but \"smart beta\" attempts to improve this by including weightages based on the other factors such as B/M, profitability, or performance such as momentum. \n",
    "\n",
    "6. Unclear what this question is referring to but I would assume no. For anyone buying to value stock, someone must deem it to be not a \"value\", for them to sell it to them. Hence, it is impossible for everyone to be exposed to the value factor. \n",
    "\n",
    "7. Standard diversification strategies goes into various sectors and asset classes that may not produce outsized returns on average. By using factors, and diversifying across higher average return factors, you could have a \"higher quality\" diversification weighted across factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def freq_multiplier(input_freq, output_freq):\n",
    "    multiplier = 1\n",
    "\n",
    "    if input_freq == 'monthly':\n",
    "        multiplier *= 12\n",
    "    elif input_freq == 'weekly':\n",
    "        multiplier *= 52\n",
    "    elif input_freq == 'daily':\n",
    "        multiplier *= 252\n",
    "    else:\n",
    "        print('invalid input frequency')\n",
    "        return\n",
    "    \n",
    "    if output_freq == 'monthly':\n",
    "        multiplier /= 12\n",
    "    elif output_freq == 'weekly':\n",
    "        multiplier /= 52\n",
    "    elif output_freq == 'daily':\n",
    "        multiplier /= 252\n",
    "    elif output_freq == 'annually':\n",
    "        pass\n",
    "\n",
    "    return multiplier\n",
    "\n",
    "def calc_stats(df, input_freq = 'monthly', output_freq = 'annually'):\n",
    "    \"\"\"\n",
    "    Returns the Performance Stats for given set of returns\n",
    "        Inputs: \n",
    "            return_data - DataFrame with Date index and Returns for different assets/strategies.\n",
    "        Output:\n",
    "            summary_stats - DataFrame with mean return, vol, sharpe ratio. Skewness, Excess Kurtosis, Var (0.5) and\n",
    "                            CVaR (0.5) and drawdown based on monthly returns. \n",
    "    \"\"\"\n",
    "    multiplier = freq_multiplier(input_freq, output_freq)\n",
    "\n",
    "    # calculate mean, vol, sharpe, VaR(5%), CVaR(5%) for each item in df\n",
    "    summary_stats = df.mean().to_frame('Mean').apply(lambda x: x * multiplier)\n",
    "    summary_stats['Volatility'] = df.std() * np.sqrt(multiplier)\n",
    "    summary_stats['Sharpe Ratio'] = summary_stats['Mean'] / summary_stats['Volatility']\n",
    "    summary_stats['Skewness'] = df.skew()\n",
    "    summary_stats['Excess Kurtosis'] = df.kurtosis()\n",
    "    summary_stats['VaR (5%)'] = df.quantile(0.05, axis = 0)\n",
    "    summary_stats['CVaR (5%)'] = df[df <= df.quantile(0.05, axis = 0)].mean()\n",
    "\n",
    "    cum_returns = (1 + df).cumprod()\n",
    "    previous_peaks = cum_returns.cummax()\n",
    "    drawdowns = (cum_returns - previous_peaks) / previous_peaks\n",
    "    summary_stats['Max Drawdown'] = drawdowns.min()\n",
    "    # find the last date of the min drawdown\n",
    "    summary_stats['Peak'] = [previous_peaks[col][:drawdowns[col].idxmin()].idxmax() for col in previous_peaks.columns]\n",
    "    summary_stats['Bottom'] = drawdowns.idxmin()\n",
    "\n",
    "    # calculate recovery time\n",
    "    recovery_date = []\n",
    "    for col in cum_returns.columns:\n",
    "        prev_max = previous_peaks[col][:drawdowns[col].idxmin()].max()\n",
    "        recovery_cum = pd.DataFrame([cum_returns[col][drawdowns[col].idxmin():]]).T\n",
    "        recovery_date.append(recovery_cum[recovery_cum[col] >= prev_max].index.min())\n",
    "    summary_stats['Recovery'] = recovery_date   \n",
    "\n",
    "    return summary_stats\n",
    "\n",
    "# tangency weights function\n",
    "def tangency_weights(df, input_freq = 'monthly', output_freq = 'annually'):\n",
    "    \"\"\"\n",
    "    Returns the weights of the tangency portfolio for given set of returns and covariance matrix\n",
    "    \"\"\"\n",
    "    multipler = freq_multiplier(input_freq, output_freq)\n",
    "\n",
    "    # calculate the mean returns and covariance matrix\n",
    "    mean_returns = df.mean() * multipler\n",
    "    cov_matrix = df.cov() * multipler\n",
    "    cov_inv = np.linalg.inv(cov_matrix)\n",
    "\n",
    "    # calculate the tangency portfolio weights\n",
    "    tangency_weights = cov_inv.dot(mean_returns)\n",
    "    tangency_weights /= tangency_weights.sum()\n",
    "\n",
    "    #create a dataframe with weights and asset names\n",
    "    tangency_weights = pd.DataFrame(tangency_weights, index = df.columns, columns = ['Weights'])\n",
    "\n",
    "    return tangency_weights\n",
    "\n",
    "def linearRegression(seriesY,seriesX):\n",
    "    \n",
    "    mean =seriesY.mean()*12\n",
    "    sharpe = mean/(seriesY.std()*(12**0.5))\n",
    "    model = sm.OLS(seriesY,sm.add_constant(seriesX)).fit()\n",
    "    rsq = model.rsquared\n",
    "    \n",
    "    beta = pd.DataFrame(index= [seriesY.name])\n",
    "    \n",
    "    for i,x in enumerate(seriesX):\n",
    "         beta[x] = model.params[i+1]\n",
    "    \n",
    "    betaCols = [i+'Beta' for i in seriesX]\n",
    "    beta = beta.rename(columns = dict(zip(beta.columns,betaCols)))\n",
    "    \n",
    "    treynor = mean/beta[beta.columns[0]]\n",
    "    alpha = model.params[0]*12\n",
    "    information = alpha/(model.resid.std()*np.sqrt(12))\n",
    "    \n",
    "    RegressionStats = pd.DataFrame({'Mean Return':mean,'Sharpe Ratio':sharpe,'R Squared':rsq,\\\n",
    "                         'Alpha':alpha, 'Information Ratio':information, 'Treynor':treynor},index= [seriesY.name])\n",
    "    \n",
    "    return pd.concat([RegressionStats,beta], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEIN = '/Users/kaiwentay/Documents/GitHub/finm-portfolio-2023/data/factor_pricing_data.xlsx'\n",
    "sheet_des = 'descriptions'\n",
    "sheet_factorexrets = 'factors (excess returns)'\n",
    "sheet_portfolioexrets = 'portfolios (excess returns)'\n",
    "sheet_rfr = 'risk-free rate'\n",
    "\n",
    "# reference github repo finm-portfolio-2023\n",
    "des = pd.read_excel(FILEIN, sheet_name = sheet_des)\n",
    "factorexrets = pd.read_excel(FILEIN, sheet_name = sheet_factorexrets).set_index('Date')\n",
    "portfolioexrets = pd.read_excel(FILEIN, sheet_name = sheet_portfolioexrets).set_index('Date')\n",
    "rfr = pd.read_excel(FILEIN, sheet_name = sheet_rfr).set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Analyze factors, similar to how you analyzed the three Fama-French factors in Homework 4. Also, report them for 3 subsamples: Beginning - 1980, 1981-2001, 2002-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>VaR (5%)</th>\n",
       "      <th>CVaR (5%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>0.084562</td>\n",
       "      <td>0.157284</td>\n",
       "      <td>0.537641</td>\n",
       "      <td>-0.07557</td>\n",
       "      <td>-0.102822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.100525</td>\n",
       "      <td>0.111476</td>\n",
       "      <td>-0.04222</td>\n",
       "      <td>-0.057663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>0.025324</td>\n",
       "      <td>0.110162</td>\n",
       "      <td>0.229880</td>\n",
       "      <td>-0.04210</td>\n",
       "      <td>-0.066904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.046525</td>\n",
       "      <td>0.083404</td>\n",
       "      <td>0.557824</td>\n",
       "      <td>-0.02768</td>\n",
       "      <td>-0.049689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>0.032492</td>\n",
       "      <td>0.073379</td>\n",
       "      <td>0.442794</td>\n",
       "      <td>-0.02754</td>\n",
       "      <td>-0.040489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.155507</td>\n",
       "      <td>0.391780</td>\n",
       "      <td>-0.06819</td>\n",
       "      <td>-0.109270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean  Volatility  Sharpe Ratio  VaR (5%)  CVaR (5%)\n",
       "MKT  0.084562    0.157284      0.537641  -0.07557  -0.102822\n",
       "SMB  0.011206    0.100525      0.111476  -0.04222  -0.057663\n",
       "HML  0.025324    0.110162      0.229880  -0.04210  -0.066904\n",
       "RMW  0.046525    0.083404      0.557824  -0.02768  -0.049689\n",
       "CMA  0.032492    0.073379      0.442794  -0.02754  -0.040489\n",
       "UMD  0.060925    0.155507      0.391780  -0.06819  -0.109270"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean, vol, sharpe, VaR(5%), CVaR(5%) for each factor\n",
    "factor_stats = calc_stats(factorexrets, input_freq = 'monthly', output_freq = 'annually')\n",
    "factor_stats.loc[:, ['Mean', 'Volatility', 'Sharpe Ratio', 'VaR (5%)', 'CVaR (5%)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>VaR (5%)</th>\n",
       "      <th>CVaR (5%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th>Factor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1980</th>\n",
       "      <th>MKT</th>\n",
       "      <td>0.202900</td>\n",
       "      <td>0.203717</td>\n",
       "      <td>0.995990</td>\n",
       "      <td>-0.082910</td>\n",
       "      <td>-0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.493472</td>\n",
       "      <td>-0.049390</td>\n",
       "      <td>-0.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>-0.198700</td>\n",
       "      <td>0.117754</td>\n",
       "      <td>-1.687412</td>\n",
       "      <td>-0.072740</td>\n",
       "      <td>-0.083300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.107800</td>\n",
       "      <td>0.073037</td>\n",
       "      <td>1.475957</td>\n",
       "      <td>-0.018800</td>\n",
       "      <td>-0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>-0.097700</td>\n",
       "      <td>0.076936</td>\n",
       "      <td>-1.269882</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>-0.056600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.307800</td>\n",
       "      <td>0.234594</td>\n",
       "      <td>1.312054</td>\n",
       "      <td>-0.079715</td>\n",
       "      <td>-0.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1981-2001</th>\n",
       "      <th>MKT</th>\n",
       "      <td>0.077257</td>\n",
       "      <td>0.157396</td>\n",
       "      <td>0.490847</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>-0.101262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.109605</td>\n",
       "      <td>0.013034</td>\n",
       "      <td>-0.043500</td>\n",
       "      <td>-0.062164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>0.063776</td>\n",
       "      <td>0.111183</td>\n",
       "      <td>0.573612</td>\n",
       "      <td>-0.041790</td>\n",
       "      <td>-0.060415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.046914</td>\n",
       "      <td>0.091606</td>\n",
       "      <td>0.512130</td>\n",
       "      <td>-0.030160</td>\n",
       "      <td>-0.057308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>0.053157</td>\n",
       "      <td>0.077355</td>\n",
       "      <td>0.687185</td>\n",
       "      <td>-0.029990</td>\n",
       "      <td>-0.041115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.101686</td>\n",
       "      <td>0.145105</td>\n",
       "      <td>0.700775</td>\n",
       "      <td>-0.060980</td>\n",
       "      <td>-0.092246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2002</th>\n",
       "      <th>MKT</th>\n",
       "      <td>0.086187</td>\n",
       "      <td>0.155313</td>\n",
       "      <td>0.554923</td>\n",
       "      <td>-0.079130</td>\n",
       "      <td>-0.099992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.018751</td>\n",
       "      <td>0.090739</td>\n",
       "      <td>0.206642</td>\n",
       "      <td>-0.039840</td>\n",
       "      <td>-0.050292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>-0.001710</td>\n",
       "      <td>0.107517</td>\n",
       "      <td>-0.015901</td>\n",
       "      <td>-0.041740</td>\n",
       "      <td>-0.072038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.043307</td>\n",
       "      <td>0.075282</td>\n",
       "      <td>0.575261</td>\n",
       "      <td>-0.025430</td>\n",
       "      <td>-0.043585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.068581</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>-0.024160</td>\n",
       "      <td>-0.037262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.009827</td>\n",
       "      <td>0.159709</td>\n",
       "      <td>0.061531</td>\n",
       "      <td>-0.073180</td>\n",
       "      <td>-0.126723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Mean  Volatility  Sharpe Ratio  VaR (5%)  CVaR (5%)\n",
       "Period    Factor                                                         \n",
       "1980      MKT     0.202900    0.203717      0.995990 -0.082910  -0.129000\n",
       "          SMB     0.053700    0.108821      0.493472 -0.049390  -0.069300\n",
       "          HML    -0.198700    0.117754     -1.687412 -0.072740  -0.083300\n",
       "          RMW     0.107800    0.073037      1.475957 -0.018800  -0.021000\n",
       "          CMA    -0.097700    0.076936     -1.269882 -0.040650  -0.056600\n",
       "          UMD     0.307800    0.234594      1.312054 -0.079715  -0.095500\n",
       "1981-2001 MKT     0.077257    0.157396      0.490847 -0.064545  -0.101262\n",
       "          SMB     0.001429    0.109605      0.013034 -0.043500  -0.062164\n",
       "          HML     0.063776    0.111183      0.573612 -0.041790  -0.060415\n",
       "          RMW     0.046914    0.091606      0.512130 -0.030160  -0.057308\n",
       "          CMA     0.053157    0.077355      0.687185 -0.029990  -0.041115\n",
       "          UMD     0.101686    0.145105      0.700775 -0.060980  -0.092246\n",
       "2002      MKT     0.086187    0.155313      0.554923 -0.079130  -0.099992\n",
       "          SMB     0.018751    0.090739      0.206642 -0.039840  -0.050292\n",
       "          HML    -0.001710    0.107517     -0.015901 -0.041740  -0.072038\n",
       "          RMW     0.043307    0.075282      0.575261 -0.025430  -0.043585\n",
       "          CMA     0.018417    0.068581      0.268543 -0.024160  -0.037262\n",
       "          UMD     0.009827    0.159709      0.061531 -0.073180  -0.126723"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report these for the following subsamples: Beginning to 1980, 1981 to 2001, 2002 to end\n",
    "# calculate mean, vol, sharpe, VaR(5%), CVaR(5%) for each factor for each subsample\n",
    "data_1980 = factorexrets.loc[:'1980']\n",
    "data_1981_2001 = factorexrets.loc['1981':'2001']\n",
    "data_2002 = factorexrets.loc['2002':]\n",
    "\n",
    "factor_stats_1980 = calc_stats(data_1980, input_freq = 'monthly', output_freq = 'annually')\n",
    "factor_stats_1981_2001 = calc_stats(data_1981_2001, input_freq = 'monthly', output_freq = 'annually')\n",
    "factor_stats_2002 = calc_stats(data_2002, input_freq = 'monthly', output_freq = 'annually')\n",
    "\n",
    "# combined summary stats for all 3 subsamples in one dataframe with period as column\n",
    "factor_stats_1980['Period'] = '1980'\n",
    "factor_stats_1981_2001['Period'] = '1981-2001'\n",
    "factor_stats_2002['Period'] = '2002'\n",
    "factor_stats_combined = pd.concat([factor_stats_1980, factor_stats_1981_2001, factor_stats_2002])\n",
    "factor_stats_combined = factor_stats_combined.reset_index().rename(columns = {'index': 'Factor'})\n",
    "factor_stats_combined = factor_stats_combined.set_index(['Period', 'Factor'])\n",
    "factor_stats_combined = factor_stats_combined.loc[:, ['Mean', 'Volatility', 'Sharpe Ratio', 'VaR (5%)', 'CVaR (5%)']]\n",
    "factor_stats_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Based on the factor statistics above, answer the following:\n",
    "#### 2.2.a Does each factor have a positive risk premium (positive expected excess return)?\n",
    "\n",
    "On aggregate, yes. However, if you see the breakdown in sub-periods:\n",
    "- 1980: HML and CMA provided a highly negative return. SMB was fairly ineffectual. The rest performed admirably. \n",
    "- 1981-2001: All of the factors turned positive in terms of excess returns but most of them lost ground with the exception of the HML and CMA.\n",
    "- 2002-End: This picture remained largely similar, with the exception of HML and CMA losing premia. \n",
    "\n",
    "#### 2.2.b Does each factor have a positive risk premium (positive expected excess return)?\n",
    "\n",
    "This isn't clearly obvious. HML had highly negative premia during the 1980s period, which could have been good in a short portfolio or as a inverse factor/indicator. It was effective during 1980-2001 time period but turned ineffective again during 2002 to present. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Report the correlation matrix across the six factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#correlation matrix across factors\n",
    "corr_matrix = factorexrets.corr()\n",
    "\n",
    "# plot correlation matrix\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.heatmap(corr_matrix, annot = True, cmap = 'Blues')\n",
    "plt.title('Correlation Matrix of Factors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.a Does the construction method succeed in keeping correlations small?\n",
    "With the exception of HML - CMA, it does seem like this construction method keeps correlation fairly low. \n",
    "\n",
    "#### 2.3.b Fama and French say that HML is somewhat redundant in their 5-factor model. Does this seem to be the case?\n",
    "Once again, this is hard to parse, but on the face of it, it does look like HML can be well explained by other factors in the model, specifically PMW and CMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Report the tangency weights for a portfolio of these 6 factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>0.369283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.307353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>0.203875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.093818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.087446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>-0.061776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Weights\n",
       "CMA  0.369283\n",
       "RMW  0.307353\n",
       "MKT  0.203875\n",
       "UMD  0.093818\n",
       "SMB  0.087446\n",
       "HML -0.061776"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tangency_weights(factorexrets).sort_values(by = 'Weights', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.a Which factors seem most important? And Least?\n",
    "The highest weight is CMA while HML provides the lowest weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.b Are the factors with low mean returns still useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Weights</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>0.084562</td>\n",
       "      <td>0.203875</td>\n",
       "      <td>0.354227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.087446</td>\n",
       "      <td>0.020134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>0.025324</td>\n",
       "      <td>-0.061776</td>\n",
       "      <td>-0.032143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW</th>\n",
       "      <td>0.046525</td>\n",
       "      <td>0.307353</td>\n",
       "      <td>0.293807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMA</th>\n",
       "      <td>0.032492</td>\n",
       "      <td>0.369283</td>\n",
       "      <td>0.246533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.093818</td>\n",
       "      <td>0.117442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean   Weights  Contribution\n",
       "MKT  0.084562  0.203875      0.354227\n",
       "SMB  0.011206  0.087446      0.020134\n",
       "HML  0.025324 -0.061776     -0.032143\n",
       "RMW  0.046525  0.307353      0.293807\n",
       "CMA  0.032492  0.369283      0.246533\n",
       "UMD  0.060925  0.093818      0.117442"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare weights to mean returns, and see the percentage contribution of each factor to the portfolio return\n",
    "comp_returns = factor_stats.loc[:, ['Mean']]\n",
    "comp_returns['Weights'] = tangency_weights(factorexrets)\n",
    "comp_returns['Contribution'] = comp_returns['Mean'] * comp_returns['Weights']\n",
    "comp_returns['Contribution'] = comp_returns['Contribution'] / comp_returns['Contribution'].sum()\n",
    "comp_returns.sort_values(by = 'Contribution', ascending = False)\n",
    "comp_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMA, SMB, and HML have the lowest mean of the combined periods. But, if we were to multiply the weights by the mean performance and find the % contribution of each of these: CMA accounts for ~25% of the performance still while SMB and HML account for 2% and -3% of the performance respectively.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.c Re-do the tangency portfolio, but this time only include MKT, SMB, HML, and UMD. Which factors get high/low tangency weights now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Weights</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKT</th>\n",
       "      <td>0.084562</td>\n",
       "      <td>0.356440</td>\n",
       "      <td>0.526603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMB</th>\n",
       "      <td>0.011206</td>\n",
       "      <td>-0.006204</td>\n",
       "      <td>-0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML</th>\n",
       "      <td>0.025324</td>\n",
       "      <td>0.348903</td>\n",
       "      <td>0.154368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.300861</td>\n",
       "      <td>0.320244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean   Weights  Contribution\n",
       "MKT  0.084562  0.356440      0.526603\n",
       "SMB  0.011206 -0.006204     -0.001215\n",
       "HML  0.025324  0.348903      0.154368\n",
       "UMD  0.060925  0.300861      0.320244"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing the tangency portfolio and returns contribution but this time only for MKT, SMB, HML and UMD\n",
    "comp_returns_2 = factor_stats.loc[['MKT', 'SMB', 'HML', 'UMD'], ['Mean']]\n",
    "comp_returns_2['Weights'] = tangency_weights(factorexrets.loc[:, ['MKT', 'SMB', 'HML', 'UMD']])\n",
    "comp_returns_2['Contribution'] = comp_returns_2['Mean'] * comp_returns_2['Weights']\n",
    "comp_returns_2['Contribution'] = comp_returns_2['Contribution'] / comp_returns_2['Contribution'].sum()\n",
    "comp_returns_2.sort_values(by = 'Contribution', ascending = False)\n",
    "comp_returns_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, now SMB has really low weights whereas the rest are fairly equal. We also have to note that our initial suggest was to remove HML. But after removing the rest of the factors, HML's contribution actually went up significant. This is probably due to HML's relatively high correlation to those removed factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Modern LPMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1\n",
    "Test the AQR 4-Factor Model using the time-series test. (We are not doing the cross-sectional\n",
    "regression tests.)\n",
    "\n",
    "(a) For each regression, report the estimated α and r-squared.\n",
    "\n",
    "(b) Calculate the mean-absolute-error of the estimated alphas, (one for each security, $\\tilde{r}^i$.)\n",
    "$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |\\hat{\\alpha}^i|$$\n",
    "If the pricing model worked, should these alpha estimates be large or small? Why? Based\n",
    "on your MAE stat, does this seem to support the pricing model or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agric</th>\n",
       "      <th>Food</th>\n",
       "      <th>Soda</th>\n",
       "      <th>Beer</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Toys</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Books</th>\n",
       "      <th>Hshld</th>\n",
       "      <th>Clths</th>\n",
       "      <th>Hlth</th>\n",
       "      <th>MedEq</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Chems</th>\n",
       "      <th>Rubbr</th>\n",
       "      <th>Txtls</th>\n",
       "      <th>BldMt</th>\n",
       "      <th>Cnstr</th>\n",
       "      <th>Steel</th>\n",
       "      <th>FabPr</th>\n",
       "      <th>Mach</th>\n",
       "      <th>ElcEq</th>\n",
       "      <th>Autos</th>\n",
       "      <th>Aero</th>\n",
       "      <th>Ships</th>\n",
       "      <th>Guns</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Mines</th>\n",
       "      <th>Coal</th>\n",
       "      <th>Oil</th>\n",
       "      <th>Util</th>\n",
       "      <th>Telcm</th>\n",
       "      <th>PerSv</th>\n",
       "      <th>BusSv</th>\n",
       "      <th>Hardw</th>\n",
       "      <th>Softw</th>\n",
       "      <th>Chips</th>\n",
       "      <th>LabEq</th>\n",
       "      <th>Paper</th>\n",
       "      <th>Boxes</th>\n",
       "      <th>Trans</th>\n",
       "      <th>Whlsl</th>\n",
       "      <th>Rtail</th>\n",
       "      <th>Meals</th>\n",
       "      <th>Banks</th>\n",
       "      <th>Insur</th>\n",
       "      <th>RlEst</th>\n",
       "      <th>Fin</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Return</th>\n",
       "      <td>0.089693</td>\n",
       "      <td>0.099669</td>\n",
       "      <td>0.108840</td>\n",
       "      <td>0.119426</td>\n",
       "      <td>0.132925</td>\n",
       "      <td>0.062946</td>\n",
       "      <td>0.118245</td>\n",
       "      <td>0.074122</td>\n",
       "      <td>0.081545</td>\n",
       "      <td>0.098083</td>\n",
       "      <td>0.080281</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.087079</td>\n",
       "      <td>0.099008</td>\n",
       "      <td>0.081380</td>\n",
       "      <td>0.099499</td>\n",
       "      <td>0.096551</td>\n",
       "      <td>0.070428</td>\n",
       "      <td>0.061145</td>\n",
       "      <td>0.090941</td>\n",
       "      <td>0.111403</td>\n",
       "      <td>0.108135</td>\n",
       "      <td>0.104150</td>\n",
       "      <td>0.088711</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.053124</td>\n",
       "      <td>0.084195</td>\n",
       "      <td>0.076038</td>\n",
       "      <td>0.088867</td>\n",
       "      <td>0.074969</td>\n",
       "      <td>0.071073</td>\n",
       "      <td>0.062545</td>\n",
       "      <td>0.089298</td>\n",
       "      <td>0.088240</td>\n",
       "      <td>0.136990</td>\n",
       "      <td>0.121310</td>\n",
       "      <td>0.099708</td>\n",
       "      <td>0.068299</td>\n",
       "      <td>0.092398</td>\n",
       "      <td>0.090785</td>\n",
       "      <td>0.085521</td>\n",
       "      <td>0.111818</td>\n",
       "      <td>0.103863</td>\n",
       "      <td>0.088988</td>\n",
       "      <td>0.095899</td>\n",
       "      <td>0.048103</td>\n",
       "      <td>0.110258</td>\n",
       "      <td>0.050820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <td>0.412541</td>\n",
       "      <td>0.660014</td>\n",
       "      <td>0.490980</td>\n",
       "      <td>0.700661</td>\n",
       "      <td>0.592263</td>\n",
       "      <td>0.252209</td>\n",
       "      <td>0.446060</td>\n",
       "      <td>0.357971</td>\n",
       "      <td>0.529226</td>\n",
       "      <td>0.437351</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>0.564162</td>\n",
       "      <td>0.627885</td>\n",
       "      <td>0.430772</td>\n",
       "      <td>0.479459</td>\n",
       "      <td>0.294980</td>\n",
       "      <td>0.444945</td>\n",
       "      <td>0.379947</td>\n",
       "      <td>0.239674</td>\n",
       "      <td>0.223263</td>\n",
       "      <td>0.395948</td>\n",
       "      <td>0.487896</td>\n",
       "      <td>0.366391</td>\n",
       "      <td>0.456119</td>\n",
       "      <td>0.340209</td>\n",
       "      <td>0.501480</td>\n",
       "      <td>0.136796</td>\n",
       "      <td>0.303234</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.391937</td>\n",
       "      <td>0.543107</td>\n",
       "      <td>0.409163</td>\n",
       "      <td>0.295240</td>\n",
       "      <td>0.473564</td>\n",
       "      <td>0.340798</td>\n",
       "      <td>0.498626</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.431349</td>\n",
       "      <td>0.360480</td>\n",
       "      <td>0.462944</td>\n",
       "      <td>0.452969</td>\n",
       "      <td>0.473165</td>\n",
       "      <td>0.596456</td>\n",
       "      <td>0.569968</td>\n",
       "      <td>0.413863</td>\n",
       "      <td>0.526738</td>\n",
       "      <td>0.192725</td>\n",
       "      <td>0.493620</td>\n",
       "      <td>0.239526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R Squared</th>\n",
       "      <td>0.341333</td>\n",
       "      <td>0.471088</td>\n",
       "      <td>0.307178</td>\n",
       "      <td>0.426698</td>\n",
       "      <td>0.272555</td>\n",
       "      <td>0.510315</td>\n",
       "      <td>0.617319</td>\n",
       "      <td>0.689702</td>\n",
       "      <td>0.560258</td>\n",
       "      <td>0.631763</td>\n",
       "      <td>0.444824</td>\n",
       "      <td>0.600067</td>\n",
       "      <td>0.503302</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.646630</td>\n",
       "      <td>0.557809</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.635205</td>\n",
       "      <td>0.630969</td>\n",
       "      <td>0.420043</td>\n",
       "      <td>0.753203</td>\n",
       "      <td>0.745137</td>\n",
       "      <td>0.555082</td>\n",
       "      <td>0.601289</td>\n",
       "      <td>0.505822</td>\n",
       "      <td>0.335597</td>\n",
       "      <td>0.050383</td>\n",
       "      <td>0.465124</td>\n",
       "      <td>0.220958</td>\n",
       "      <td>0.465899</td>\n",
       "      <td>0.356958</td>\n",
       "      <td>0.589162</td>\n",
       "      <td>0.582222</td>\n",
       "      <td>0.852923</td>\n",
       "      <td>0.669483</td>\n",
       "      <td>0.738742</td>\n",
       "      <td>0.753552</td>\n",
       "      <td>0.737682</td>\n",
       "      <td>0.676739</td>\n",
       "      <td>0.586154</td>\n",
       "      <td>0.707433</td>\n",
       "      <td>0.756767</td>\n",
       "      <td>0.683464</td>\n",
       "      <td>0.643047</td>\n",
       "      <td>0.772044</td>\n",
       "      <td>0.685298</td>\n",
       "      <td>0.603615</td>\n",
       "      <td>0.812962</td>\n",
       "      <td>0.595904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.011434</td>\n",
       "      <td>0.019555</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>-0.032189</td>\n",
       "      <td>0.031788</td>\n",
       "      <td>-0.030329</td>\n",
       "      <td>-0.005510</td>\n",
       "      <td>-0.011724</td>\n",
       "      <td>-0.037288</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>-0.023092</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>-0.028386</td>\n",
       "      <td>-0.028049</td>\n",
       "      <td>-0.034357</td>\n",
       "      <td>-0.025503</td>\n",
       "      <td>-0.020730</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.014419</td>\n",
       "      <td>-0.008997</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>-0.019166</td>\n",
       "      <td>-0.034908</td>\n",
       "      <td>-0.022503</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>-0.052220</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>0.042445</td>\n",
       "      <td>0.066834</td>\n",
       "      <td>0.061967</td>\n",
       "      <td>0.029572</td>\n",
       "      <td>-0.037549</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>-0.017072</td>\n",
       "      <td>-0.013517</td>\n",
       "      <td>0.019527</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>-0.022979</td>\n",
       "      <td>-0.008563</td>\n",
       "      <td>-0.056717</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>-0.045176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Information Ratio</th>\n",
       "      <td>0.053788</td>\n",
       "      <td>0.104111</td>\n",
       "      <td>0.105981</td>\n",
       "      <td>0.187339</td>\n",
       "      <td>0.184497</td>\n",
       "      <td>-0.184306</td>\n",
       "      <td>0.193848</td>\n",
       "      <td>-0.262943</td>\n",
       "      <td>-0.053928</td>\n",
       "      <td>-0.086150</td>\n",
       "      <td>-0.214220</td>\n",
       "      <td>0.205774</td>\n",
       "      <td>0.269910</td>\n",
       "      <td>-0.227710</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>-0.154731</td>\n",
       "      <td>-0.255470</td>\n",
       "      <td>-0.223848</td>\n",
       "      <td>-0.142866</td>\n",
       "      <td>-0.099392</td>\n",
       "      <td>-0.011482</td>\n",
       "      <td>0.034557</td>\n",
       "      <td>0.073244</td>\n",
       "      <td>-0.062402</td>\n",
       "      <td>-0.228170</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.099598</td>\n",
       "      <td>-0.135801</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>0.053416</td>\n",
       "      <td>-0.381370</td>\n",
       "      <td>-0.005064</td>\n",
       "      <td>0.285142</td>\n",
       "      <td>0.475933</td>\n",
       "      <td>0.470018</td>\n",
       "      <td>0.249783</td>\n",
       "      <td>-0.348573</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>-0.157477</td>\n",
       "      <td>-0.151638</td>\n",
       "      <td>0.185137</td>\n",
       "      <td>0.022844</td>\n",
       "      <td>-0.223835</td>\n",
       "      <td>-0.083839</td>\n",
       "      <td>-0.360927</td>\n",
       "      <td>0.188842</td>\n",
       "      <td>-0.334950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Treynor</th>\n",
       "      <td>0.107052</td>\n",
       "      <td>0.146377</td>\n",
       "      <td>0.138704</td>\n",
       "      <td>0.165106</td>\n",
       "      <td>0.180305</td>\n",
       "      <td>0.056362</td>\n",
       "      <td>0.094682</td>\n",
       "      <td>0.066563</td>\n",
       "      <td>0.108322</td>\n",
       "      <td>0.087683</td>\n",
       "      <td>0.076983</td>\n",
       "      <td>0.115765</td>\n",
       "      <td>0.140059</td>\n",
       "      <td>0.077077</td>\n",
       "      <td>0.092901</td>\n",
       "      <td>0.066399</td>\n",
       "      <td>0.078416</td>\n",
       "      <td>0.072226</td>\n",
       "      <td>0.050262</td>\n",
       "      <td>0.056237</td>\n",
       "      <td>0.073939</td>\n",
       "      <td>0.088841</td>\n",
       "      <td>0.083196</td>\n",
       "      <td>0.091421</td>\n",
       "      <td>0.073053</td>\n",
       "      <td>0.132855</td>\n",
       "      <td>0.094710</td>\n",
       "      <td>0.070344</td>\n",
       "      <td>0.063303</td>\n",
       "      <td>0.088657</td>\n",
       "      <td>0.137166</td>\n",
       "      <td>0.085418</td>\n",
       "      <td>0.057809</td>\n",
       "      <td>0.082107</td>\n",
       "      <td>0.080198</td>\n",
       "      <td>0.112078</td>\n",
       "      <td>0.099246</td>\n",
       "      <td>0.088845</td>\n",
       "      <td>0.067432</td>\n",
       "      <td>0.094565</td>\n",
       "      <td>0.083035</td>\n",
       "      <td>0.082898</td>\n",
       "      <td>0.113938</td>\n",
       "      <td>0.109533</td>\n",
       "      <td>0.076764</td>\n",
       "      <td>0.097882</td>\n",
       "      <td>0.040084</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>0.047921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MKTBeta</th>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.680903</td>\n",
       "      <td>0.784688</td>\n",
       "      <td>0.723330</td>\n",
       "      <td>0.737220</td>\n",
       "      <td>1.116824</td>\n",
       "      <td>1.248868</td>\n",
       "      <td>1.113566</td>\n",
       "      <td>0.752802</td>\n",
       "      <td>1.118614</td>\n",
       "      <td>1.042843</td>\n",
       "      <td>0.876772</td>\n",
       "      <td>0.730212</td>\n",
       "      <td>1.129765</td>\n",
       "      <td>1.065742</td>\n",
       "      <td>1.225619</td>\n",
       "      <td>1.268867</td>\n",
       "      <td>1.336787</td>\n",
       "      <td>1.401215</td>\n",
       "      <td>1.087275</td>\n",
       "      <td>1.229938</td>\n",
       "      <td>1.253950</td>\n",
       "      <td>1.299762</td>\n",
       "      <td>1.139232</td>\n",
       "      <td>1.214326</td>\n",
       "      <td>0.823450</td>\n",
       "      <td>0.560907</td>\n",
       "      <td>1.196900</td>\n",
       "      <td>1.201187</td>\n",
       "      <td>1.002366</td>\n",
       "      <td>0.546555</td>\n",
       "      <td>0.832063</td>\n",
       "      <td>1.081919</td>\n",
       "      <td>1.087577</td>\n",
       "      <td>1.100272</td>\n",
       "      <td>1.222273</td>\n",
       "      <td>1.222322</td>\n",
       "      <td>1.122269</td>\n",
       "      <td>1.012861</td>\n",
       "      <td>0.977081</td>\n",
       "      <td>1.093328</td>\n",
       "      <td>1.031640</td>\n",
       "      <td>0.981389</td>\n",
       "      <td>0.948235</td>\n",
       "      <td>1.159250</td>\n",
       "      <td>0.979743</td>\n",
       "      <td>1.200074</td>\n",
       "      <td>1.238895</td>\n",
       "      <td>1.060498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMLBeta</th>\n",
       "      <td>0.178699</td>\n",
       "      <td>0.169841</td>\n",
       "      <td>0.206106</td>\n",
       "      <td>0.025183</td>\n",
       "      <td>0.249344</td>\n",
       "      <td>-0.035336</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.265474</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.049475</td>\n",
       "      <td>0.117548</td>\n",
       "      <td>-0.147144</td>\n",
       "      <td>-0.159870</td>\n",
       "      <td>0.289457</td>\n",
       "      <td>0.098180</td>\n",
       "      <td>0.532835</td>\n",
       "      <td>0.313205</td>\n",
       "      <td>0.266041</td>\n",
       "      <td>0.338470</td>\n",
       "      <td>0.176516</td>\n",
       "      <td>0.093030</td>\n",
       "      <td>-0.007111</td>\n",
       "      <td>0.183877</td>\n",
       "      <td>0.290246</td>\n",
       "      <td>0.417844</td>\n",
       "      <td>0.264897</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>0.326034</td>\n",
       "      <td>0.537158</td>\n",
       "      <td>0.627247</td>\n",
       "      <td>0.317718</td>\n",
       "      <td>0.104903</td>\n",
       "      <td>0.153490</td>\n",
       "      <td>-0.127397</td>\n",
       "      <td>-0.465209</td>\n",
       "      <td>-0.855465</td>\n",
       "      <td>-0.538878</td>\n",
       "      <td>-0.362816</td>\n",
       "      <td>0.243555</td>\n",
       "      <td>0.116515</td>\n",
       "      <td>0.189071</td>\n",
       "      <td>0.099153</td>\n",
       "      <td>-0.140767</td>\n",
       "      <td>0.080657</td>\n",
       "      <td>0.721895</td>\n",
       "      <td>0.479804</td>\n",
       "      <td>0.490751</td>\n",
       "      <td>0.327216</td>\n",
       "      <td>0.087573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMWBeta</th>\n",
       "      <td>-0.006405</td>\n",
       "      <td>0.507359</td>\n",
       "      <td>0.494736</td>\n",
       "      <td>0.600586</td>\n",
       "      <td>0.657434</td>\n",
       "      <td>0.230797</td>\n",
       "      <td>-0.109524</td>\n",
       "      <td>0.177919</td>\n",
       "      <td>0.485108</td>\n",
       "      <td>0.564987</td>\n",
       "      <td>0.454208</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>0.210362</td>\n",
       "      <td>0.297728</td>\n",
       "      <td>0.139608</td>\n",
       "      <td>0.289758</td>\n",
       "      <td>0.384226</td>\n",
       "      <td>0.218419</td>\n",
       "      <td>-0.451780</td>\n",
       "      <td>-0.073052</td>\n",
       "      <td>-0.128851</td>\n",
       "      <td>0.098948</td>\n",
       "      <td>0.047432</td>\n",
       "      <td>0.373064</td>\n",
       "      <td>0.438418</td>\n",
       "      <td>0.627627</td>\n",
       "      <td>-0.036594</td>\n",
       "      <td>0.054946</td>\n",
       "      <td>-0.278670</td>\n",
       "      <td>0.150687</td>\n",
       "      <td>0.212875</td>\n",
       "      <td>-0.062412</td>\n",
       "      <td>0.300333</td>\n",
       "      <td>0.019408</td>\n",
       "      <td>-0.492153</td>\n",
       "      <td>-0.141328</td>\n",
       "      <td>-0.486099</td>\n",
       "      <td>-0.341097</td>\n",
       "      <td>0.412502</td>\n",
       "      <td>0.255496</td>\n",
       "      <td>0.352329</td>\n",
       "      <td>0.185132</td>\n",
       "      <td>0.347550</td>\n",
       "      <td>0.500334</td>\n",
       "      <td>0.087560</td>\n",
       "      <td>0.222779</td>\n",
       "      <td>0.062269</td>\n",
       "      <td>-0.401302</td>\n",
       "      <td>0.117101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMDBeta</th>\n",
       "      <td>0.084119</td>\n",
       "      <td>0.045146</td>\n",
       "      <td>-0.087111</td>\n",
       "      <td>0.090319</td>\n",
       "      <td>-0.026824</td>\n",
       "      <td>-0.150169</td>\n",
       "      <td>-0.230768</td>\n",
       "      <td>-0.077390</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>-0.202276</td>\n",
       "      <td>0.086577</td>\n",
       "      <td>0.049555</td>\n",
       "      <td>0.062399</td>\n",
       "      <td>-0.107454</td>\n",
       "      <td>-0.074495</td>\n",
       "      <td>-0.342219</td>\n",
       "      <td>-0.091214</td>\n",
       "      <td>0.015867</td>\n",
       "      <td>-0.165963</td>\n",
       "      <td>-0.182834</td>\n",
       "      <td>-0.133222</td>\n",
       "      <td>-0.049913</td>\n",
       "      <td>-0.378461</td>\n",
       "      <td>-0.129595</td>\n",
       "      <td>-0.051373</td>\n",
       "      <td>0.039940</td>\n",
       "      <td>0.073549</td>\n",
       "      <td>-0.142204</td>\n",
       "      <td>0.143339</td>\n",
       "      <td>0.060929</td>\n",
       "      <td>0.099185</td>\n",
       "      <td>-0.081872</td>\n",
       "      <td>0.088880</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.206289</td>\n",
       "      <td>-0.081450</td>\n",
       "      <td>-0.127313</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>-0.084701</td>\n",
       "      <td>-0.117838</td>\n",
       "      <td>-0.094835</td>\n",
       "      <td>0.011102</td>\n",
       "      <td>-0.054203</td>\n",
       "      <td>-0.067775</td>\n",
       "      <td>-0.138145</td>\n",
       "      <td>-0.014815</td>\n",
       "      <td>-0.196719</td>\n",
       "      <td>-0.038805</td>\n",
       "      <td>-0.022131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Agric     Food      Soda   ...     RlEst     Fin       Other\n",
       "Mean Return        0.089693  0.099669  0.108840  ...  0.048103  0.110258  0.050820\n",
       "Sharpe Ratio       0.412541  0.660014  0.490980  ...  0.192725  0.493620  0.239526\n",
       "R Squared          0.341333  0.471088  0.307178  ...  0.603615  0.812962  0.595904\n",
       "Alpha              0.009491  0.011434  0.019555  ... -0.056717  0.018242 -0.045176\n",
       "Information Ratio  0.053788  0.104111  0.105981  ... -0.360927  0.188842 -0.334950\n",
       "Treynor            0.107052  0.146377  0.138704  ...  0.040084  0.088997  0.047921\n",
       "MKTBeta            0.837838  0.680903  0.784688  ...  1.200074  1.238895  1.060498\n",
       "HMLBeta            0.178699  0.169841  0.206106  ...  0.490751  0.327216  0.087573\n",
       "RMWBeta           -0.006405  0.507359  0.494736  ...  0.062269 -0.401302  0.117101\n",
       "UMDBeta            0.084119  0.045146 -0.087111  ... -0.196719 -0.038805 -0.022131\n",
       "\n",
       "[10 rows x 49 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqr = factorexrets[['MKT', 'HML', 'RMW', 'UMD']]\n",
    "\n",
    "frames = []\n",
    "for col in portfolioexrets:\n",
    "    p = linearRegression(portfolioexrets[col],aqr)\n",
    "    frames.append(p) \n",
    "AQRRegression = pd.concat(frames)\n",
    "AQRRegression.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for AQR factors: 0.022995\n"
     ]
    }
   ],
   "source": [
    "AQR_MAE = round(abs(AQRRegression['Alpha']).mean(),6)\n",
    "print(f'Mean Absolute Error for AQR factors: {AQR_MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test the CAPM, FF 3-Factor Model and the the FF 5-Factor Model. Report the MAE statistic for each of these models and compare it with the AQR Model MAE. Which model fits best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for CAPM Model: 0.020608\n"
     ]
    }
   ],
   "source": [
    "capm = factorexrets[['MKT']]\n",
    "\n",
    "frames = []\n",
    "for col in portfolioexrets:\n",
    "    p = linearRegression(portfolioexrets[col],capm)\n",
    "    frames.append(p) \n",
    "CAPMRegression = pd.concat(frames)\n",
    "CAPM_MAE = round(abs(CAPMRegression['Alpha']).mean(),6)\n",
    "print(f'Mean Absolute Error for CAPM Model: {CAPM_MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for FF-3 Factor Model: 0.0242\n"
     ]
    }
   ],
   "source": [
    "ff3 = factorexrets[['MKT', 'SMB', 'HML']]\n",
    "\n",
    "frames = []\n",
    "for col in portfolioexrets:\n",
    "    p = linearRegression(portfolioexrets[col],ff3)\n",
    "    frames.append(p) \n",
    "FF3Regression = pd.concat(frames)\n",
    "FF3_MAE = round(abs(FF3Regression['Alpha']).mean(),6)\n",
    "print(f'Mean Absolute Error for FF-3 Factor Model: {FF3_MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for FF-5 Factor Model: 0.031272\n"
     ]
    }
   ],
   "source": [
    "ff5 = factorexrets[['MKT', 'SMB', 'HML', 'RMW', 'CMA']]\n",
    "frames = []\n",
    "for col in portfolioexrets:\n",
    "    p = linearRegression(portfolioexrets[col],ff5)\n",
    "    frames.append(p) \n",
    "FF5Regression = pd.concat(frames)\n",
    "FF5_MAE = abs(FF3Regression['Alpha']).mean()\n",
    "FF5_MAE = round(abs(FF5Regression['Alpha']).mean(),6)\n",
    "print(f'Mean Absolute Error for FF-5 Factor Model: {FF5_MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CAPM</th>\n",
       "      <td>0.020608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AQR</th>\n",
       "      <td>0.022995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF-3</th>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF-5</th>\n",
       "      <td>0.031272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MAE\n",
       "CAPM  0.020608\n",
       "AQR   0.022995\n",
       "FF-3  0.024200\n",
       "FF-5  0.031272"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE_TS = pd.DataFrame({'MAE':[CAPM_MAE,AQR_MAE,FF3_MAE,FF5_MAE]}, index = [\"CAPM\",\"AQR\",\"FF-3\",\"FF-5\"])\n",
    "MAE_TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the pricing models are effective then the magnitude of the alpha estimates should be small as that would imply that the model factors adequately reflect the observed asset returns. Overall the MAE is fairly close to 0 for each pricing model and so the models are fairly accurate. Based only on the MAE statistic, we'd conclude that the CAPM Model is most accurate and the Fama-French 5-Factor Model is least accurate. However as we've discussed in class, this is not the case in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Does any particular factor seem especially important or unimportant for pricing? Do you think Fama and French should use the Momentum Factor?\n",
    "The AQR model performs well with regards to the MAE results seeing as how it contains the second highest number of factors and the second lowest MAE (behind CAPM which should practically be discarded). This makes a decent practical case for including the momentum factor in the Fama French model. \n",
    "\n",
    "Beyond that, we also notice that with the increase in factors, we actually get a higher MAE which means their is diminishing returns in this case for adding more factors. This could be due to the fact that either the 3 factors have adequately explained most of the performance or that the additional factors are not useful factors to improving performance or explain any uncorrelated performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 This does not matter for pricing, but report the average (across n estimations) of the time-series regression r-squared statistics. Do this for each of the three models you tested. Do these models lead to high time-series r-squared stats? That is, would these factors be good in a Linear Factor Decomposition of the assets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average R Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CAPM</th>\n",
       "      <td>0.528087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AQR</th>\n",
       "      <td>0.577081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF3</th>\n",
       "      <td>0.572516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF5</th>\n",
       "      <td>0.597519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Average R Squared\n",
       "CAPM           0.528087\n",
       "AQR            0.577081\n",
       "FF3            0.572516\n",
       "FF5            0.597519"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAPM_RSq = CAPMRegression['R Squared'].mean()\n",
    "AQR_RSq = AQRRegression['R Squared'].mean()\n",
    "FF3_RSq = FF3Regression['R Squared'].mean()\n",
    "FF5_RSq = FF5Regression['R Squared'].mean()\n",
    "Average_R_Squared = pd.Series({'CAPM':CAPM_RSq,'AQR':AQR_RSq,'FF3':FF3_RSq,'FF5':FF5_RSq})\n",
    "Average_R_Squared.to_frame(\"Average R Squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average R-Squared stats are in the interval 0.5 - 0.6 for each of the models tested. This means that there is moderate explainability using these factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 We tested three models using the time-series tests (focusing on the time-series alphas.) Re-test these models, but this time use the cross-sectional test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Series Premia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKTBeta</th>\n",
       "      <td>0.084562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMBBeta</th>\n",
       "      <td>0.011206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMLBeta</th>\n",
       "      <td>0.025324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMWBeta</th>\n",
       "      <td>0.046525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMABeta</th>\n",
       "      <td>0.032492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMDBeta</th>\n",
       "      <td>0.060925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time Series Premia\n",
       "MKTBeta            0.084562\n",
       "SMBBeta            0.011206\n",
       "HMLBeta            0.025324\n",
       "RMWBeta            0.046525\n",
       "CMABeta            0.032492\n",
       "UMDBeta            0.060925"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_premia = (factorexrets.mean()*12).to_frame('Time Series Premia')\n",
    "time_series_premia.index = [x+\"Beta\" for x in time_series_premia.index]\n",
    "time_series_premia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQR CS Premia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKTBeta</th>\n",
       "      <td>0.087644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMLBeta</th>\n",
       "      <td>-0.039757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMWBeta</th>\n",
       "      <td>0.044399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMDBeta</th>\n",
       "      <td>0.053375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AQR CS Premia\n",
       "MKTBeta       0.087644\n",
       "HMLBeta      -0.039757\n",
       "RMWBeta       0.044399\n",
       "UMDBeta       0.053375"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = AQRRegression['Mean Return']\n",
    "x = AQRRegression[['MKTBeta','HMLBeta','RMWBeta','UMDBeta']]\n",
    "AQRRegressionCS = sm.OLS(y,x,missing='drop').fit()\n",
    "AQR_CS_MAE = abs(AQRRegressionCS.resid).mean()\n",
    "AQR_CS_premia = AQRRegressionCS.params.to_frame(\"AQR CS Premia\")\n",
    "AQR_CS_premia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FF3 CS Premia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKTBeta</th>\n",
       "      <td>0.101569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMBBeta</th>\n",
       "      <td>-0.064615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMLBeta</th>\n",
       "      <td>-0.017476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FF3 CS Premia\n",
       "MKTBeta       0.101569\n",
       "SMBBeta      -0.064615\n",
       "HMLBeta      -0.017476"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = FF3Regression['Mean Return']\n",
    "x = FF3Regression[['MKTBeta','SMBBeta','HMLBeta']]\n",
    "FF3RegressionCS = sm.OLS(y,x,missing='drop').fit()\n",
    "FF3_CS_MAE = abs(FF3RegressionCS.resid).mean()\n",
    "FF3_CS_Premia = FF3RegressionCS.params.to_frame(\"FF3 CS Premia\")\n",
    "FF3_CS_Premia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FF5 CS Premia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKTBeta</th>\n",
       "      <td>0.095697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMBBeta</th>\n",
       "      <td>-0.057674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMLBeta</th>\n",
       "      <td>-0.033504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMWBeta</th>\n",
       "      <td>0.035899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMABeta</th>\n",
       "      <td>-0.015156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FF5 CS Premia\n",
       "MKTBeta       0.095697\n",
       "SMBBeta      -0.057674\n",
       "HMLBeta      -0.033504\n",
       "RMWBeta       0.035899\n",
       "CMABeta      -0.015156"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = FF5Regression['Mean Return']\n",
    "x = FF5Regression[['MKTBeta','SMBBeta','HMLBeta','RMWBeta','CMABeta']]\n",
    "FF5RegressionCS = sm.OLS(y,x,missing='drop').fit()\n",
    "FF5_CS_MAE = abs(FF5RegressionCS.resid).mean()\n",
    "FF5_CS_Premia = FF5RegressionCS.params.to_frame(\"FF5 CS Premia\")\n",
    "FF5_CS_Premia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.a Report the time-series premia of the factors (just their sample averages,) and compare to the cross-sectionally estimated premia of the factors. Do they differ substantially?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Series Premia</th>\n",
       "      <th>AQR CS Premia</th>\n",
       "      <th>FF3 CS Premia</th>\n",
       "      <th>FF5 CS Premia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKTBeta</th>\n",
       "      <td>0.084562</td>\n",
       "      <td>0.087644</td>\n",
       "      <td>0.101569</td>\n",
       "      <td>0.095697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMBBeta</th>\n",
       "      <td>0.011206</td>\n",
       "      <td></td>\n",
       "      <td>-0.064615</td>\n",
       "      <td>-0.057674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMLBeta</th>\n",
       "      <td>0.025324</td>\n",
       "      <td>-0.039757</td>\n",
       "      <td>-0.017476</td>\n",
       "      <td>-0.033504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMWBeta</th>\n",
       "      <td>0.046525</td>\n",
       "      <td>0.044399</td>\n",
       "      <td></td>\n",
       "      <td>0.035899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMABeta</th>\n",
       "      <td>0.032492</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0.015156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMDBeta</th>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.053375</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time Series Premia AQR CS Premia FF3 CS Premia FF5 CS Premia\n",
       "MKTBeta            0.084562      0.087644      0.101569      0.095697\n",
       "SMBBeta            0.011206                   -0.064615     -0.057674\n",
       "HMLBeta            0.025324     -0.039757     -0.017476     -0.033504\n",
       "RMWBeta            0.046525      0.044399                    0.035899\n",
       "CMABeta            0.032492                                 -0.015156\n",
       "UMDBeta            0.060925      0.053375                            "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([time_series_premia,AQR_CS_premia,FF3_CS_Premia,FF5_CS_Premia],axis = 1).fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.b Report the MAE of the cross-sectional regression residuals for each of the four models, (the υi.) How do they compare to the MAE of the time-series alphas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAE (CS)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AQR</th>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.016395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF-3</th>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.015031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF-5</th>\n",
       "      <td>0.031272</td>\n",
       "      <td>0.012982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MAE  MAE (CS)\n",
       "AQR   0.022995  0.016395\n",
       "FF-3  0.024200  0.015031\n",
       "FF-5  0.031272  0.012982"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE_CS = pd.Series([AQR_CS_MAE,FF3_CS_MAE, FF5_CS_MAE], index = MAE_TS.index[1:])\n",
    "MAE = pd.concat([MAE_TS,MAE_CS],axis = 1)\n",
    "MAE.columns = ['MAE','MAE (CS)']\n",
    "MAE[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE of Cross Section regression is in general lower than the MAE of Time Series Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
